{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.insert(0, \"../lib\")\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n",
    "os.environ[\"NLTK_DATA\"] = \"../\"\n",
    "nltk.data.path.append(\"../nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set = pd.read_csv('../data/dataset.csv',sep=\"\\t\", header=None, encoding=\"utf8\")\n",
    "df_set = df_set.rename(index = int, columns = {0: \"comment\"})\n",
    "\n",
    "df_labels = pd.read_csv('../data/labels.csv',sep=\"\\t\", header=None, encoding=\"utf8\")\n",
    "df_labels = df_labels.rename(index = int, columns = {0: \"result\"})\n",
    "\n",
    "df_raw = pd.concat([df_set, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>fonctions de pré-traitement</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    replace_chars = [\n",
    "        [r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \"\", True],\n",
    "        [r'[\\w\\.-]+@[\\w\\.-]+', \"\", True],\n",
    "        [r'<.*?>', \"\", True],\n",
    "        [\"\\\"\", \"\", False],\n",
    "        [\".\", \" . \", False],\n",
    "        [\",\", \" , \", False],\n",
    "        [\";\", \" ; \", False],\n",
    "        [\"?\", \" ? \", False],\n",
    "        [\":\", \" : \", False],\n",
    "        [\"!\", \" ! \", False],\n",
    "        [\" '\", \" \", False],\n",
    "        [\"' \", \" \", False]\n",
    "    ]\n",
    "\n",
    "    for e in replace_chars:\n",
    "        if (e[2]):\n",
    "            text = re.sub(e[0], e[1], text, flags=re.MULTILINE)\n",
    "        else:\n",
    "            text = text.replace(e[0], e[1])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tags(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokens)   \n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tags(tags, ls):\n",
    "    r = []\n",
    "    \n",
    "    for e in tags:\n",
    "        for t in ls:\n",
    "            if e[1] == t:\n",
    "                r.append(e[0])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_traitement(text):\n",
    "    text = clean_text(text)\n",
    "    tags = text_to_tags(text)\n",
    "    filtered_tags = filter_tags(tags, [\"JJ\", \"JJS\", \"JJR\", \"RBR\", \"RBS\"])\n",
    "    \n",
    "    return filtered_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(df):\n",
    "    size = df.shape[0]\n",
    "    \n",
    "    data = {\n",
    "        \"filtered_tags\": [],\n",
    "        \"text_filtered_tags\": [],\n",
    "        \"clean_comment\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        text = df[\"comment\"][i]\n",
    "        filtered_tags = pre_traitement(text)\n",
    "        \n",
    "        text_filtered_tags = \"\"\n",
    "        \n",
    "        for e in filtered_tags:\n",
    "            text_filtered_tags += \" \" + e\n",
    "        \n",
    "        data[\"filtered_tags\"].append(filtered_tags)\n",
    "        data[\"text_filtered_tags\"].append(text_filtered_tags)\n",
    "        data[\"clean_comment\"].append(clean_text(text))\n",
    "    \n",
    "    df_temp = pd.DataFrame(data)\n",
    "    df_result = pd.concat([df, df_temp], axis=1)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>application des différents traitement</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_clean = parse_df(df_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test des classifiers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>import des librairies</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(clf, x, y, min_df = 0.0015, max_df=0.3, ngram_range=(1,3), is_to_array=False):\n",
    "    vectorizer = TfidfVectorizer(min_df = min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    k_fold = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "    x = vectorizer.fit_transform(x)\n",
    "    \n",
    "    if is_to_array: x = x.toarray()\n",
    "    \n",
    "    clf.fit(x, y)\n",
    "    \n",
    "    r = {\"clf\": clf, \"k_fold\": k_fold, \"vectorizer\": vectorizer, \"x\": x}\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_classification(clf, k_fold, x, y):\n",
    "    score = cross_val_score(clf, x, y, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "    print('Les différentes accuracy pour les 10 évaluations sont :')\n",
    "    print(score)\n",
    "    print ('Accuracy moyenne :', score.mean())\n",
    "    print('standard deviation', score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MultinomialNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont :\n",
      "[0.906 0.899 0.908 0.911 0.914 0.905 0.918 0.919 0.913 0.916]\n",
      "Accuracy moyenne : 0.9109\n",
      "standard deviation 0.006040695324215587\n"
     ]
    }
   ],
   "source": [
    "r = classification(\n",
    "    MultinomialNB(),\n",
    "    data_clean[\"clean_comment\"],\n",
    "    data_clean[\"result\"]\n",
    ")\n",
    "\n",
    "clf_multi_nb = r[\"clf\"]\n",
    "k_fold = r[\"k_fold\"]\n",
    "vectorizer_multi_nb = r[\"vectorizer\"]\n",
    "\n",
    "scoring_classification(\n",
    "    clf_multi_nb,\n",
    "    k_fold,\n",
    "    r[\"x\"],\n",
    "    data_clean[\"result\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GaussianNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont :\n",
      "[0.871 0.866 0.875 0.888 0.862 0.886 0.873 0.867 0.874 0.88 ]\n",
      "Accuracy moyenne : 0.8741999999999999\n",
      "standard deviation 0.008022468448052638\n"
     ]
    }
   ],
   "source": [
    "r = classification(\n",
    "    GaussianNB(),\n",
    "    data_clean[\"clean_comment\"],\n",
    "    data_clean[\"result\"],\n",
    "    ngram_range=(1,3),\n",
    "    is_to_array=True\n",
    ")\n",
    "\n",
    "clf_gaussian = r[\"clf\"]\n",
    "k_fold = r[\"k_fold\"]\n",
    "vectorizer_gaussian = r[\"vectorizer\"]\n",
    "\n",
    "scoring_classification(\n",
    "    clf_gaussian,\n",
    "    k_fold,\n",
    "    r[\"x\"],\n",
    "    data_clean[\"result\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DecisionTreeClassifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont :\n",
      "[0.732 0.745 0.755 0.736 0.745 0.749 0.729 0.748 0.737 0.735]\n",
      "Accuracy moyenne : 0.7411000000000001\n",
      "standard deviation 0.008018104514160447\n"
     ]
    }
   ],
   "source": [
    "r = classification(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    data_clean[\"text_filtered_tags\"],\n",
    "    data_clean[\"result\"],\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "clf_tree = r[\"clf\"]\n",
    "k_fold = r[\"k_fold\"]\n",
    "vectorizer_tree = r[\"vectorizer\"]\n",
    "\n",
    "scoring_classification(\n",
    "    clf_tree,\n",
    "    k_fold,\n",
    "    r[\"x\"],\n",
    "    data_clean[\"result\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test des classifiers sur un jeu de test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_predict_test(df_test, predicted):\n",
    "    size = df_test.shape[0]\n",
    "    avg = 0;\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        result = df_test[\"result\"][i]\n",
    "        \n",
    "        if (predicted[i] == result):\n",
    "            avg += 1\n",
    "    \n",
    "    return (float(avg) / float(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv',sep=\"\\t\", header=None, encoding=\"utf8\")\n",
    "del df_test[0]\n",
    "df_test = df_test.rename(index = int, columns = {1: \"comment\", 2: \"result\"})\n",
    "df_test = parse_df(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB: 0.86416\n",
      "DecisionTreeClassifier 0.76006\n"
     ]
    }
   ],
   "source": [
    "x_test_multi_nb = vectorizer_multi_nb.transform(df_test[\"clean_comment\"])\n",
    "predict_multi_nb = clf_multi_nb.predict(x_test_multi_nb)\n",
    "\n",
    "#x_test_gaussian = vectorizer_gaussian.transform(df_test[\"clean_comment\"]).toarray()\n",
    "#predict_gaussian = clf_gaussian.predict(x_test_gaussian)\n",
    "\n",
    "x_test_tree = vectorizer_tree.transform(df_test[\"text_filtered_tags\"])\n",
    "predict_tree = clf_tree.predict(x_test_tree)\n",
    "\n",
    "print(\"MultinomialNB:\", average_predict_test(df_test, predict_multi_nb))\n",
    "#print(\"GaussianNB:\", average_predict_test(df_test, predict_gaussian))\n",
    "print(\"DecisionTreeClassifier\", average_predict_test(df_test, predict_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' other short few short only violent many horrible like whole other good enough least x good'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('(', '('),\n",
       " ('actually', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('Family', 'NNP'),\n",
       " ('Portraits', 'NNP'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('contains', 'VBZ'),\n",
       " ('Cutting', 'VBG'),\n",
       " ('Moments', 'NNS'),\n",
       " ('+', '$'),\n",
       " ('2', 'CD'),\n",
       " ('other', 'JJ'),\n",
       " ('short', 'JJ'),\n",
       " ('films', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('Douglas', 'NNP'),\n",
       " ('Buck', 'NNP'),\n",
       " (')', ')'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Mar', 'NNP'),\n",
       " ('del', 'FW'),\n",
       " ('Plata', 'NNP'),\n",
       " ('festival', 'NN'),\n",
       " ('(', '('),\n",
       " ('Argentina', 'NNP'),\n",
       " (')', ')'),\n",
       " ('...', ':'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('watch', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('cover', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('eyes', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('1st', 'CD'),\n",
       " ('half', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Cutting', 'VBG'),\n",
       " ('Moments', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('take', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('peek', 'NN'),\n",
       " ('every', 'DT'),\n",
       " ('once', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('while', 'NN'),\n",
       " ('.', '.'),\n",
       " ('By', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('over', 'RB'),\n",
       " (',', ','),\n",
       " ('my', 'PRP$'),\n",
       " ('stomach', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('upside', 'RB'),\n",
       " ('down', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('felt', 'VBD'),\n",
       " ('light', 'NN'),\n",
       " ('headed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('HAD', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('leave', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('cinema', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('minutes', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('2nd', 'CD'),\n",
       " ('short', 'JJ'),\n",
       " ('begun', 'VBN'),\n",
       " ('(', '('),\n",
       " ('BTW', 'NNP'),\n",
       " (',', ','),\n",
       " ('of', 'IN'),\n",
       " ('course', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('only', 'JJ'),\n",
       " ('one', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('left', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('room', 'NN'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('WAAAAY', 'NNP'),\n",
       " ('too', 'RB'),\n",
       " ('violent', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('disgusting', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('impressed', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('many', 'JJ'),\n",
       " ('brave', 'VBP'),\n",
       " ('people', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('actually', 'RB'),\n",
       " ('loved', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('get', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('love', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('movies', 'NNS'),\n",
       " ('!', '.'),\n",
       " ('The', 'DT'),\n",
       " ('shocking', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('bloody', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('horrible', 'JJ'),\n",
       " ('images', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('saw', 'VBD'),\n",
       " ('got', 'VBD'),\n",
       " ('really', 'RB'),\n",
       " ('stuck', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('head', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('like', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('also', 'RB'),\n",
       " ('try', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('analyze', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('story', 'NN'),\n",
       " ('(', '('),\n",
       " ('my', 'PRP$'),\n",
       " ('boyfriend', 'NN'),\n",
       " ('did', 'VBD'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('whole', 'JJ'),\n",
       " ('thing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('told', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('about', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (')', ')'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('think', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('any', 'DT'),\n",
       " ('sense', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('mean', 'VBP'),\n",
       " (',', ','),\n",
       " ('that', 'DT'),\n",
       " ('amount', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('violence', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('stuff', 'NN'),\n",
       " (',', ','),\n",
       " ('makes', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('sense', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('try', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('shock', 'VB'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('enough', 'JJ'),\n",
       " ('reason', 'NN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('think', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('There', 'EX'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('absolutely', 'RB'),\n",
       " ('nothing', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('``', '``'),\n",
       " ('Well', 'NNP'),\n",
       " (',', ','),\n",
       " ('at', 'IN'),\n",
       " ('least', 'JJS'),\n",
       " (\"'x\", 'POS'),\n",
       " (\"'\", \"''\"),\n",
       " ('thing', 'NN'),\n",
       " ('about', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('well', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('guess', 'VBP'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('never', 'RB'),\n",
       " ('understand', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('films', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_clean[\"text_filtered_tags\"][4000])\n",
    "display(text_to_tags(data_clean[\"comment\"][4000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
